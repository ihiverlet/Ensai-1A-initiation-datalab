
# D√©couverte du Datalab

## Introduction 
<details>
Le Datalab permet aux statisticiens de d√©couvrir, d'exp√©rimenter, d'apprendre, de se former aux outils de la data.

### Pourquoi un Datalab ? 
#### Une r√©ponse √† un besoin
Dans le monde professionnel, plusieurs probl√®mes se posent au statisticien :

- sa machine n'est pas assez puissante
- des probl√®mes de r√©plicabilit√© (le fameux √ßa marche sur mon ordi !)
- besoin de connaissances sp√©cifiques pour installer des logiciels
...

√Ä l'INSEE, un projet est n√© pour pallier √† ce besoin : [Onyxia](https://www.onyxia.sh/){target="_blank"}. L'Insee met une instance de ce projet √† disposition des administrations publiques et √©coles : le [SSP Cloud](https://datalab.sspcloud.fr/){target="_blank"}.
Vous avez √©galement acc√®s √† une seconde instance d'Onyxia g√©r√©e par le GENES. N'h√©sitez pas √† cr√©er un compte sur ces deux plateformes. Ces instances sont administr√©es par diff√©rentes √©quipes et proposent une offre de service diff√©rente. En cas de probl√®me vous avez diff√©rents canaux de communication :
pour le sspcloud : il faudra vous cr√©er un compte slack
pour l'instance du denes: vous avez un canal teams d√©di√©

A noter, tout le [code](https://github.com/InseeFrLab/onyxia){target="_blank"}. est opensource (ie: droit en lecture, libre redistribution du code, modification du code et utilisation du code). Ainsi, n'importe qui peut installer son propre datalab en se basant sur Onyxia ! 

#### Des concepts
Derri√®re Onyxia se cachent plusieurs concepts: l'utilisation de techbologies cloud natives, avoir une infrastructures qui permet d'avoir des ressources de calculs (CPU, RAM, GPU) et de stockage √† disposition, avoir une interface graphique pour simplifier la vie des utilisateurs... Gr√¢ce √† Onyxia un data scientists n'a pas besoin de connaissances sp√©cifiques (Docker, Kubernetes, Helm, S3... ) pour obtenir un environnement de ravail.  La plateforme se pr√©sente comme un bac √† sable et permet notamment de tester de nouvelles technologies et de se former en se concentrant sur le contenu plut√¥t que sur la configuration d'un environnement de travail. D'ailleurs vous utiliserez les datalabs au cours de vos prochains tp :)
Les datalabs donnent aux utilisateurs la possibilit√© de lancer de nombreux services pr√©configur√©s √† la demande (Jupyter, Rstudio, VSCode, PostgreSQL... et pleins d'autres n'h√©sitez pas √† regarder !) avec une puissance de calcul adapt√©e aux besoins.
L'utilisateur n'a pas besoin de connaissances sp√©cifiques pour lancer un service mais s'il le d√©sire, il peut se former : toutes les commandes que vous pourriez ex√©cuter en ligne de commande sont visibles dans l'interface. 
Les choix faits dans Onyxia sont conditionn√©s par le fait qu'il ne faut pas s'enfermer, le but est de rendre le logiciel facultatif. De sorte √† ne pas s'enfermer dans un choix technologique et qu'il soit couteux d'en sortir.

:warning:
Ne d√©posez *jamais* de donn√©es sensibles sur le sspcloud ou l'instance du GENES ! D'ailleurs, il n'y a aucune garantie de service sur le sspcloud : la plateforme peut tomber en panne, il peut y avoir des attaques... donc soyez vigilants √† vos usages.

Pour les fonctionnaires, une autre instance nomm√©e LS3 (accessible en interne et coup√©e d'internet) permet l'utilisation de donn√©es sensibles.
Pour les ing√©nieurs, vous retrouverez peut-√™tre d'autres instances d'onyxia sur vos futurs postes ;) 

NB: On distinguera 3 notions primordiales au cours du tp : l'environnement d'ex√©cution du code, le stockage des donn√©es et la sauvegarde du code

</details>

## Objectifs 

Ce TP d'initiation vous permettra de faire vos premiers pas sur la plateforme :
 
- Lancer vos premiers services
- Configurer votre compte sur le datalab
- Vous familiariser avec l'espace de stockage S3
- Sauvegarder votre code, vos donn√©es
- Adopter de **bonnes pratiques** et **ne pas perdre votre travail** üòá

## Cr√©er un compte

Vous pouvez r√©aliser ce TP soit sur :

- Le [Datalab du GENES](https://onyxia.lab.groupe-genes.fr/){target="_blank"} 
- Le [Datalab SSPCloud de l'INSEE](https://datalab.sspcloud.fr/){target="_blank"} 
  - Pour la cr√©ation de compte, utilisez votre mail ENSAI prenom.nom@eleve.ensai.fr

## Lancer un service

### Diff√©rents catalogues de services

- [ ] Allez dans `Catalogue de services`

Vous trouverez diff√©rents catalogues : que ce soit pour les environnements de d√©veloppement int√©ractifs (IDE), les bases de donn√©es, de la datavisualisation...
Cette ann√©e vous vous servirez principalement des services IDE et bases de donn√©es. Mais n'h√©sitez pas √† faire un tour sur les autres catalogueus tout au long de votre scolarit√© !

### Un premier service

- [ ] S√©lectionnez le service de votre choix *Vscode-python* ou *Jupyter-python* puis cliquez sur `Lancer`

Vous obtiendrez un formulaire vous laissant de multiples options pour configurer votre service. Pour une exp√©rience "de base", ne les modifiez pas et cliquez sur "lancer".
Attendez quelques secondes le temps que le service se lance. Lisez bien la note qui s'affiche √† l'√©cran ! Elle contient des informations essentielles comme vos identifiants de connection par exemple.  

- [ ] Cliquez pour copier le mot de passe
- [ ] Cliquez sur `Ouvrir le service` :rocket:
  - password : collez le mot de passe

Votre service s'ouvre. Vous pouvez alors commencer √† coder :)

## Configurer son service

Maintenant que nous savons lancer un service, revenons un petit peu en arri√®re et int√©ressons nous au formulaire pr√©sent lors du lancement du service. (Onglet 'Catalogue de services' et s√©lectionner un service vscode-python par exemple)

* Onglet *Service* : Ici, vous disposez de la possibilit√© de choisir la version de python que vous souhaitez utiliser

* Onglet *Resources(CPU/RAM)* : vous choisissez les ressources dont disposera votre service. Notamment, vous choisissez les ressources qui seront garanties au lancement du service (requests) et les ressources qui pourront √™tre utilis√©es au maximum par votre service (limits).  
CPU (processeur) : il s'agit de la puissance de calcul allou√©e au service. Les CPU ex√©cutent les instructions (ouvrir un programme, calculer, afficher des r√©sulats) 
RAM (m√©moire vive): il s'agit de la m√©moire de travail du service, elle garde temporairement ce que le service utilise pendant l'ex√©cution: les dataframes, mod√®les, images. Elle n‚Äôest pas persistante : si le service s‚Äôarr√™te, la RAM est vid√©e (les fichiers survivent s‚Äôils sont sur le volume persistant).

* Onglet *Configuration for persistence* : d√©termine la taille du disque de travail ‚Äúqui survit‚Äù quand le service est "ferm√©". Sans persistance, les services tournent dans des conteneurs √©ph√©m√®res : tout ce qui est seulement dedans peut dispara√Ætre √† l‚Äôarr√™t. Avec la persistance, un volume de stockage est attach√© √† ta session et conserve tes fichiers jusqu'√† la d√©sinstallation du service.

## Premiers pas dans un service

- [ ] Cr√©ez un Notebook Python (fichier .ipynb)
- [ ] V√©rifiez que tout fonctionne bien, √©crivez et ex√©cutez une fonction python de votre choix, cr√©ez des dossiers, des fichiers, les renommer, supprimer, d√©placer...

Un terminal est un outil qui vous permet de communiquer avec votre machine en lignes de commande. Ainsi, vous √©crivez des commandes (instructions) dans une fen√™tre que la machine ex√©cutera. Vous pouvez donc utiliser un terminal pour ex√©cuter du code, manager vos fichiers, installer des outils, des packages, ...  

Sur le sspcloud, le terminal utilise Bash (un des langages les plus courants). Apprendre quelques commandes de base vous simplifiera la vie.

- [ ]  Ouvrir un terminal : dans le menu, View ‚Üí Terminal 
  - savoir o√π vous vous situez: `pwd` (print work directory)
  - lister les fichiers : `ls` (list)
  - cr√©er un dossier : `mkdir mon-dossier` (make directory)
  - se d√©placer dans le fichier : cd `mon-dossier` (change directory)
  - cr√©er un fichier : `touch mon-fichier`
  - suprimer un fichier: `rm mon-fichier` (remove)
  - installer un package : `uv add my-package`, `pip install my-package` ...

- [ ] Fermer la fen√™tre, fermer le navigateur... Pas de panique, retrouvez votre service (dans le volet "Mes services" sur le datalab)

Imaginons que vous aviez des t√¢ches sp√©cifiques √† r√©aliser et que votre travail est fini, vous supprimez votre service. Cela lib√®re les ressources de calcul r√©serv√©es. O√π est votre code ?  üí• perdu, disparu, irr√©cup√©rable...

- [ ] Supprimer votre service
- [ ] Constater que le front cesse de fonctionner et ... que ce que vous aviez fait est perdu pour toujours

Pas de solution miracle, si √ßa vous arrive, il faudra tout recommencer. Comment √©viter √ßa ? En sauvegardant votre code et vos donn√©es. 

Une option tr√®s rh√©barbative et encourageant les erreurs serait de vous faire t√©l√©charger vos fichiers. Mais c'est tr√®s p√©nible surtout quand vous commencez √† avoir beaucoup de fichiers et pleins de versions diff√©rentes.
Nous allons donc utiliser un outil d√©di√© √† la gestion de versions de code: git. Cet outils est d'autant plus utile qu'il facilite la collaboration sur un projet.

## Git

Git est un outil de gestion de versions. Vous l'utiliserez en compl√©ment d'une forge telle que github ou gitlab qui permettra de stocker votre code. Git vous permettra d'avoir une gestion propre de vos fichiers et de naviguer dans l'historique de votre code, voir les modifications apport√©es au fil du temps etc. 
Vous aurez bient√¥t un cours d√©di√© √† git donc on ne rentrera pas dans les d√©tails ici. 

NB : Le repo clon√© est public et donc accessible √† tous. Il se peut que vous ayez parfois besoin de travailler sur des repos priv√©s. Il vous faudra donc renseigner un token qui permettra de vous authentifier. Pour vous √©viter d'avoir √† renseigner vos credentials √† chaque fois que vous aurez besoin de vous authentifier, vous avez la possibilit√© de renseigner vos informations de connexion au sein du datalab dans l'onglet "Mon compte" > "Git". Les credentials d√©finis seront alors inject√©s dans vos services sous forme de variable d'environnement.

- [ ] Se rendre dans l'onglet "Mon compte" puis l'onglet "Git"
Bonus : Ajouter ses donn√©es d'authentification et faire ses premiers pas avec git, voir la fin du TP ou https://docs.sspcloud.fr/content/version-control.html#cr%C3%A9er-un-jeton-dacc%C3%A8s-token

- [ ] Cloner le repo du TP
- [ ] Afficher les diff√©rentes contributions 

Dans un terminal, effectuer les commandes suivantes : 
```
git clone <le TP>
cd <le TP>
git log --one-line
```
Vous venez de cr√©er une copie en local du repo distant et d'afficher l'historique des contributions au projet

NB: Il est aussi possible de r√©aliser ces √©tapes en passant par l'interface (*Source Control* symbole sur la gauche avec des branches)

- [ ] Configurer un nouveau service √† son lancement (onglet "Git") pour que le repo soit clon√© directement 

Comment synchroniser ce que vous avez en local ? et √† distance ? La r√©ponse d√©but octobre. Et si vous √™tes curieux, voici quelques ressources : 
En revanche n'h√©sitez pas √† lire "le tuto" & les "formations" sur le sujet: https://www.sspcloud.fr/catalog?path=Bonnes%E2%90%A3pratiques%E2%90%A3de%E2%90%A3d%C3%A9veloppement%E2%90%A3avec%E2%90%A3Git%E2%90%A3et%E2%90%A3R

et √† faire la partie suivante : 

## Bonus : Aller plus loin avec Git 

### G√©n√©rer un token GitHub

Si vous avez d√©j√† g√©n√©r√© et d√©clar√© un jeton GitHub, inutile de refaire ces 2 √©tapes.

- [ ] Connectez-vous √† votre compte GitHub
- [ ] Allez dans settings :arrow_right: Developer settings :arrow_right: Personal access tokens :arrow_right: Tokens (classic)
- [ ] G√©n√©rez un [nouveau jeton classique](https://github.com/settings/tokens/new){target="_blank"}
  - Renseigner : 
    - nom du token : Datalab GENES
    - date d'expiration :arrow_right: Custom :arrow_right: 1 an
  - :white_check_mark: Cochez repo
  - Cliquez sur [Generate token]{.green-button}
  - Copiez ce jeton commen√ßant par `ghp_` et gardez le pr√©cieusement de c√¥t√© quelques minutes

:warning: 
- Ce jeton ne sera visible qu'une seule fois
- si vous le perdez ou s'il est expir√©, il faut en g√©n√©rer un nouveau


### D√©clarer votre jeton

GitHub vous a fournit un jeton. Il faut maintenant le d√©clarer sur le Datalab :

- [ ] Allez dans `Mon Compte` :arrow_right: Onglet `Git`
- [ ] Renseignez les informations suivantes 
  - nom d'utilisateur Git 
  - mail (celui utilis√© pour votre compte GitHub)
- [ ] Collez votre token

Vous pouvez maintenant √©changer du code entre les services du Datalab et vos d√©p√¥ts GitHub. :tada:


### D√©p√¥t pour le code

Avant de cr√©er un service, nous allons cr√©er un d√©p√¥t GitHub qui permettra de sauvegarder votre code.

- [ ] Dans GitHub, cr√©er un [nouveau Repository](https://github.com/new){target="_blank"}
  - Repository name : TP-datalab
  - Private
  - :white_check_mark: Cochez *Add a README file*
  - .gitignore template : Python
  - [Create Repository]{.green-button}
- [ ] Sur la page de votre repo, cliquez sur le bouton [Code]{.green-button}
- [ ] Copiez l'adresse *https* du repo


### Branchez votre service sur un r√©po

Lors du lancement d'un *Service*, vous pouvez vous brancher sur un r√©po git. Ainsi le contenu de votre d√©p√¥t sera import√© dans votre service.

Vous pourrez alors utiliser le code de votre d√©p√¥t et √©ventuellement le mettre √† jour en effectuant un *push*.

Lancez un service *Jupyter Notebook*

- [ ] Ouvrez la Configuration
  - De nombreux onglets permettent de configurer votre service
  - Service : possibilit√© d'utiliser une autre image Docker
  - Resources : choisir CPU et RAM
  - Init : script √† lancer au d√©marrage
- [ ] Allez dans l'onglet `Git` et collez l'adresse *https* du repo dans la case *Repository url*
- [ ] `Lancez` le service, puis attendez quelques secondes


### Sauver son code

- [ ] Sur Jupyter, ouvrez un terminal
  - File :arrow_right: New :arrow_right: Terminal
- [ ] Positionnez-vous dans le repo : `cd /home/onyxia/work/TP-datalab/`
- [ ] `git status` pour voir l'√©tat actuel
  - le fichier *ex0.ipynb* doit appara√Ætre dans les *Untracked files*
- [ ] Ajoutez ce fichier √† l'index
- [ ] Cr√©ez un commit
- [ ] Poussez ce commit vers votre d√©p√¥t distant (GitHub)
  - Vous pouvez v√©rifier sur GitHub que votre fichier *ex0.ipynb* est bien pr√©sent

- `git add .` ## Attention, √† utliser avec pr√©caution
- `git commit -m "cr√©ation fichier tp"`
- `git push`


Vous savez d√©sormais lancer des services et enregistrer votre code. Mais en tant que data scientist le coeur de m√©tier ce sont... les donn√©es !
Comment les importer et les sauvegarder apr√®s des traitements informatiques ?


## Stockage S3

Les datalabs vous proposent de stocker vos donn√©es sur un espace d√©di√© √† cet effet en utilisant S3 (Simple Storage System). S3 est un **protocole de stockage objet** d√©riv√© du service initialement offert par le cloud provider AWS.  

Vous aurez toujours besoin des deux √©l√©ments suivants : 
- URL de base du serveur S3 h√©berg√© sur le sspcloud : https://minio.lab.sspcloud.fr  
- Nom du bucket auquel vous souhaitez acc√©der; si vous souhaitez acc√©der √† votre bucket personnel, il s'agit de votre nom d'utilisateur sur le sspcloud 

Un bucket correspond en gros √† un dossier √† la racine du serveur S3. Les buckets permettent de s√©parer les usages, les permissions, les quotas ...  
En fonction du serveur S3 que vous utilisez et des permissions que vous avez, vous pouvez avoir acc√®s √† tout ou partie d'un ou plusieurs buckets.

### Authentification

A part pour l'acc√®s aux donn√©es explicitement rendues publiques (la gestion de la visibilit√© et des permissions sur les fichiers se fait en g√©n√©ral via un syst√®me de policies qui n'est pas abord√© ici), il faudra des informations d'authentification (credentials) pour communiquer avec l'API.  
Ces credentials sont constitu√©s d'un duo `access key` & `secret key` (en gros login / mot de passe) pour les comptes de service et d'un trio `access key`, `secret key`, `session token` pour les identit√©s temporaires (credentials personnels, expirant au bout d'un certain temps).  

Pourront √™tre utilis√©es les variables d'environnements () suivantes, g√©n√©ralement reconnues par les biblioth√®ques standards S3 :

AWS_ACCESS_KEY_ID=my_access_key
AWS_SECRET_ACCESS_KEY=my_secret_key
AWS_SESSION_TOKEN = my_session_token
ENDPOINT_URL = s3_endpoint

Pour r√©cup√©rer vos credentials, vous pouvez vous rendre sur 
- SSPCLOUD : onglet my account > Connect to storage et s√©lectionner `shell environment variable`

### Un client pour communiquer avec S3

Afin de simplifier les int√©ractions avec l'API S3, nous allons utiliser un client s3. 

Des exemples de clients s3 en ligne de commande :  

- [mc](https://min.io/docs/minio/linux/reference/minio-mc.html) (minIO Client) : compatible pour tout service compatible s3
- [aws cli](https://aws.amazon.com/cli/) : outil officiel pour int√©ragir avec Amazon S3

Il existe √©videmment des interfaces graphiques ainsi que des biblioth√®ques (SDK) pour tous les langages.  
Vous √™tes libres d'utiliser le client S3 de votre choix, en fonction de vos pr√©f√©rences.  
Dans la suite on illustrera √† partir du client `mc` pr√©configur√© sur le datalab.  


### Cas d'usages et limites  

S3 (et plus g√©n√©ralement le stockage objet) est parfait pour un certain nombre d'usages mais pas tous.  
Les principales limitations sont les suivantes :  

- **L'√©criture partielle n'est pas possible** : un fichier ne peut pas √™tre modifi√©. La moindre modification (y compris renommage) correspond √† la r√©√©criture compl√®te du fichier  
- **La latence est plus forte que pour un stockage block / fichiers classique** : il n'est donc pas adapt√© pour des syst√®mes ayant besoin d'une latence faible comme les bases de donn√©es relationnelles  

Du coup on en tire quelques le√ßons :  

- Write once, read many (WORM): S3 est particuli√®rement adapt√© √† ce pattern. Parfait pour les backups, les logs, les ressources statiques, la diffusion des repertoires
- S3 n'a pas vocation √† remplacer enti√®rement les stockages block / fichiers existants mais √† venir en compl√©ment pour les bons cas d'usage

#### Aller plus loin 

https://github.com/InseeFrLab/ecosysteme-data/tree/main/source/s3
https://docs.sspcloud.fr/content/storage.html
https://pythonds.linogaliana.fr/content/modern-ds/s3.html#les-donn%C3%A9es-sur-le-cloud


#### Revenons au TP
Lorsque l'on travaille dans le cloud, il est essentiel de [s√©parer les donn√©es des programmes]{.underline} pour :

- mieux g√©rer les ressources
- renforcer la s√©curit√© en limitant les acc√®s et les permissions
- permettre une scalabilit√© ind√©pendante des composants
- Un m√™me code peut tourner sur plusieurs jeux de donn√©es. 

### Votre bucket

Un **bucket** est un conteneur de stockage utilis√© pour regrouper des objets (fichiers et m√©tadonn√©es) dans des syst√®mes de stockage de type cloud. Il facilite l'organisation, la gestion des permissions et l'acc√®s aux donn√©es dans un espace de stockage structur√©.

Lors de votre cr√©ation de compte, un bucket est cr√©√© avec votre nom d'utilisateur. Dans ce bucket, vous pouvez :

- cr√©er / supprimer des dossiers
- importer / supprimer des fichiers

Vous avez plusieurs possibilit√©s pour g√©rer votre stockage :

- Depuis le Datalab, onglet *Mes fichiers*
- Depuis un terminal avec un client comme le client Minio `mc`


### Stocker vos fichiers

- [ ] T√©l√©chargez ce fichier [parquet](data/.parquet){target="_blank"}

Ensuite, allez sur la page d'accueil du Datalab :

- [ ] Allez dans `Mes fichiers`
- [ ] Cr√©ez un dossier `Initiation` par exemple (organiser vos donn√©es comme vous le souhaitez !)
- [ ] T√©l√©versez votre fichier *parquet* dans le dossier `Initiation`

Vous remarquerez √† droite, un encadr√© vert avec des lignes de commande du type `mc cp my-file.parquet s3/<username>/Initiation/my-file.parquet`.

Ce sont des commandes pour interagir avec votre stockage depuis un terminal (voir ci-apr√®s).

Cependant, vous pouvez extraire de ces commandes une information int√©ressante : le chemin vers votre fichier : `s3/<username>/initiation/my-file.parquet`.

- [ ] Visualisez les donn√©es gr√¢ce √† l'explorateur de donn√©es 

### Client MinIO

Le [client MinIO](https://min.io/docs/minio/linux/reference/minio-mc.html){target="_blank"} install√© et [utilisable depuis le terminal]{.underline} permet √©galement d'interagir avec vos fichiers.

Ouvrez un terminal (File :arrow_right: New :arrow_right: Terminal):

- [ ] `mc ls s3/<username>/` : pour lister le contenu de votre dossier
- [ ] `mc cp s3/<username>/output.csv .` : pour copier le fichier depuis s3 dans votre dossier courant 
  - le fichier apparait dans votre explorer
- [ ] Supprimez ce fichier car importer les fichiers de donn√©es dans son espace de travail n'est pas une bonne pratique : `rm output.csv`

La commande `mc --help` liste toutes les commandes possibles (ESPACE pour d√©filer, CTRL+C pour sortir)


### Utiliser des donn√©es

Sur la page d'accueil du Datalab :

- [ ] Allez dans `Mon Compte`, puis dans l'onglet `Connexion au Stockage`

Vous trouverez ici des informations pour vous connecter au stockage selon le language que vous utilisez : Python, R...
D'ailleurs pour chaque langage, il y a m√™me plusieurs packages qui font le job. Par exemple *s3fs* ou *boto3* pour Python.

Retournez dans votre service Notebook Jupyter :

- [ ] Cr√©ez un nouveau Notebook
  - vous pouvez par exemple le nommer `S3.ipynb`
- [ ] Cr√©er des cellules, puis collez, comprenez et ex√©cutez les blocs de code ci-dessous.

Commencez par importer les packages n√©cessaires et r√©cup√©rer les valeurs des variables d'environnement pour pouvoir vous connecter √† votre stockage.

```python
import os

s3_endpoint = f'https://{os.environ["AWS_S3_ENDPOINT"]}'
s3_access_key = os.environ["AWS_ACCESS_KEY_ID"]
s3_secret_access_key = os.environ["AWS_SECRET_ACCESS_KEY"]
s3_session_token = os.environ["AWS_SESSION_TOKEN"]
s3_region = os.environ["AWS_DEFAULT_REGION"]

```

:warning:
Les cl√©s et les jetons ont une dur√©e de vie limit√©e. Si vous laissez votre service ouvert trop longtemps (√† √©viter !), vos cl√©s et jetons pourraient √™tre expir√©s.
Dans ce cas, vous devrez recharger des nouvelles valeurs (voir Mon Compte > Connexion au Stockage).

D√©finissez le chemin o√π se trouve votre fichier et lisez le avec pandas.

Rappel : Vous ne devriez jamais √©crire vos mots de passe dans le code, utilisez des variables d'environnement √† la place !  


De plus, les noms de ces variables d'environnement correspondent aux variables reconnues par la plupart des librairies. Ainsi, pour lire un fichier csv, il vous suffit d'√©crire le code suivant :

```python
df = pd.read_csv("s3://inesh/diffusion/airports_fr.csv")

```
Si vos services n'√©taient pas correctement configur√©s, vous devriez plut√¥t √©crire le code suivant :

```python

import os, pandas as pd

storage_opts = {
    "key": os.environ["AWS_ACCESS_KEY_ID"],
    "secret": os.environ["AWS_SECRET_ACCESS_KEY"],
    "token": os.environ.get("AWS_SESSION_TOKEN"), 
    "client_kwargs": {
        "region_name": "eu-west-1",
        "endpoint_url": "https://minio.lab.sspcloud.fr"
    }
}
df = pd.read_csv("s3://inesh/diffusion/airports_fr.csv", storage_options=storage_opts)

```

Ou bien, en cr√©ant un filesystem:

```python
import os, s3fs, pandas as pd

# Create filesystem object
S3_ENDPOINT_URL = "https://" + os.environ["AWS_S3_ENDPOINT"]
fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})

# Lister les objets d'un bucket
fs.ls("donnees-insee")

# Importer des donn√©es

BUCKET = "donnees-insee"
FILE_KEY_S3 = "diffusion/BPE/2019/BPE_ENS.csv"
FILE_PATH_S3 = BUCKET + "/" + FILE_KEY_S3

with fs.open(FILE_PATH_S3, mode="rb") as file_in:
    df_bpe = pd.read_csv(file_in, sep=";")

# Exporter des donn√©es

BUCKET_OUT = "<mon_bucket>"
FILE_KEY_OUT_S3 = "mon_dossier/BPE_ENS.csv"
FILE_PATH_OUT_S3 = BUCKET_OUT + "/" + FILE_KEY_OUT_S3

with fs.open(FILE_PATH_OUT_S3, 'w') as file_out:
    df_bpe.to_csv(file_out)

```

Dans tous les cas, votre **guide de survie** pour lire des donn√©es (autre qu'une bonne recherche google) se trouve ici : https://www.sspcloud.fr/document?path=SSPCloud%E2%90%A3Documentation%E2%80%BAUsing%E2%90%A3the%E2%90%A3Datalab%E2%80%BAData%E2%90%A3storage


### Donn√©es d'autres utilisateurs

Ce fichier est stock√© sur le bucket d'un autre utilisateur √† l'adresse suivante :

- SSP Cloud : `s3://inesh/diffusion/fichier.parquet`

Malheureusement, la fonctionnalit√© n'est pas encore impl√©ment√©e sur le Datalab du GENES. Les dossiers *diffusion* de chaque utilisateur ne sont pas accessibles en lecture. Il faudra les rendre accessibles soi-m√™me.

√Ä la racine de votre Bucket, vous pouvez cr√©er un dossier nomm√© `diffusion`.

Vous pourrez alors stocker √† l'int√©rieur les dossiers et fichiers que vous souhaitez partager aux autres utilisateurs. Ils auront un droit d'acc√®s en lecture sur votre dossier *diffusion*.

De la m√™me fa√ßon, vous pouvez rendre un fichier accessible aux autres utilisateurs depuis l'interface (symbole oeil) ou en ligne de commande en utilisant mc et obtenir un lien de t√©l√©chargement.


### Exportez vos r√©sultats vers MinIO

Vous pouvez √©galement exporter vos fichiers vers S3.

Nous allons utiliser ici la librairie [s3fs](https://s3fs.readthedocs.io/){target="_blank"}.

- [ ] Collez et lancez ce code :

```python
  import s3fs
  
  fs = s3fs.S3FileSystem(
      client_kwargs={'endpoint_url': 'https://'+'minio-simple.lab.groupe-genes.fr'},
      key = os.environ["AWS_ACCESS_KEY_ID"], 
      secret = os.environ["AWS_SECRET_ACCESS_KEY"], 
      token = os.environ["AWS_SESSION_TOKEN"])
  
  destination = f"s3://{s3_username}/initiation/output.csv"
  
  with fs.open(destination, mode='wb') as f:
      top10f2021.write_csv(f)
```

- [ ] Sur le Datalab, allez dans `Mes fichiers` > `initiation`
  - le fichier *output.csv* a √©t√© g√©n√©r√©
  - rafraichissez la page si besoin
- [ ] Double-cliquez sur ce fichier pour en avoir un aper√ßu


``` python
  import pandas
  df = pandas.read_csv('FD_INDREG_2015.txt', sep=';', nrows=10)
  df.to_csv('FD_LOGEMT_2015_first_10.csv', sep=',')

read_csv charge en m√©moire (BTW : m√©moire vs disque) permettant traitements rapides
to_csv √©crit le fichier sur disque

  
time python -c "import pandas; pandas.read_csv('FD_INDREG_2015.txt', sep=';').to_csv('FD_INDREG_2015.csv', sep=',')"


rm FD_INDREG_2015.txt
python
  import pandas
  df = pandas.read_csv('s3://donnees-insee/diffusion/RP/2015/FD_INDREG_2015.txt', sep=';', nrows=10)
-> √ßa va vite, pas d'espace disque requis
  df.to_csv('s3://bucket/FD_INDREG_2015.csv', sep=',')
```

Vous avez cr√©√© un processus r√©plicable, qui traite un fichier sur S3 et √©crit le r√©sultat sur S3


# Behind the scene

Onyxia injecte des variables d'environnement afin de vous proposer un environnement pr√©configur√©.

Pour acc√©der √† ces variables: 
- depuis un terminal 
```
env   #beaucoup beaucoup beaucoup de choses
env | grep AWS    # toutes les variables d'environnement qui contiennent AWS
echo $AWS_ACCESS_KEY_ID   # affiche la valeur de la variable d'environnement
```
- avec python
```python
  import os
  os.environ
```
- avec R 
```r
Sys.getenv()
```
Les variables d'environnement sont accessibles √† tous les programmes qui tournent sur le service.

## Configurer son service 

Comme nous l'avons vu plus t√¥t, il peut √™tre utile de configurer son service
- CPU/RAM/Persistence
- Variable d'env : pour en ajouter si besoin
- S3 config : injection de variable d'env pour faire marcher S3
Onyxia retient ces param√®tres pour vous
- Git

-> vous pouvez les retrouver et/ou les modifer dans "Mon compte"


## Bonus
### Surveiller son service

- [ ] Sur la page du Datalab, allez dans `Mes services`
- [ ] Cliquez sur le nom du service (Jupyter-python)
- [ ] Cliquez sur `Surveillance externe`

Vous arrivez sur la page de l'outil **Grafana** qui permet d'observer les m√©triques de votre service.


### Les secrets

::: {.callout-important title="Enigme du P√®re Fouras" icon="false"}
Plus j'ai de gardiens, moins je suis gard√©.

Moins j'ai de gardiens, plus je suis gard√©.

Qui suis-je ?
:::

Certains √©l√©ments ne doivent pas √™tre diffus√©s dans votre code (jetons d'acc√®s, mots de passe...).

Pour √©viter d'avoir √† nettoyer votre code √† chaque fois que vous le poussez sur GitHub, le datalab propose de g√©rer vos secrets.

#### Cr√©er un secret

- [ ] Allez dans *Mes secrets*
- [ ] Cr√©ez un `Nouveau secret` nomm√© *projet_patate*
- [ ] Double-cliquez pour ouvrir ce secret
- [ ] `Ajoutez une variable`
  - Nom : PATATE_TOKEN
  - Valeur : 123456
  - Cliquez sur :white_check_mark: pour valider
- [ ] Ajoutez une autre variable
  - Nom : PATATE_PORT
  - Valeur : 5236
  - Cliquez sur :white_check_mark: pour valider

#### Utiliser dans un service

- [ ] Pr√©parez le lancement d'un service Rstudio
- [ ] Dans la configuration, allez dans l'onglet `Vault`
- [ ] secret : *projet_patate*
- [ ] Lancez le service

Dans votre servives, les deux variables d'environnement ont √©t√© cr√©√©es. 

- [ ] V√©rifiez leur pr√©sence via le terminal : `env | grep PATATE` ou `echo $PATATE_TOKEN`
- [ ] Ouvrez un notebook et r√©cup√©rez la valeur de *PATATE_TOKEN*
  ```{.python}
  import os

  token = os.environ["PATATE_TOKEN"]
  print(token)
  ```
- [ ] Une fois que vous avez fini de jouer, supprimez votre service

### Personnaliser son service

- Utiliser un script d'initialisation
- Utilser sa propre image Docker


## Lib√©rer les ressources 

Une fois vos travaux termin√©s, il est temps de lib√©rer les ressources r√©serv√©es.

- [ ] N'oubliez pas d'enregistrer votre code (git)
- [ ] N'oubliez pas d'enregistrer vos donn√©es (s3)
- [ ] Puis sur la page d'accueil, allez dans *Mes services*, mettez votre service √† la poubelle 

Vous pouvez ais√©ment reproduire votre travail plus tard :

- Votre code est t√©l√©charg√©
- Vos donn√©es sont toujours sur MinIO
- Il suffit de relancer un nouveau service et de relancer les calculs


### Besoin d'assistance ? 

- Contactez l'√©quipe du SSP Cloud sur [Slack](https://join.slack.com/t/3innovation/shared_invite/zt-1bo6y53oy-Y~zKzR2SRg37pq5oYgiPuA){target="_blank"}
- Pour le Datalab du GENES, vous trouverez sur la page d'accueil un lien pour rejoindre le canal Teams


### Bibliographie 
- [Le SSPCLOUD : une fabrique cr√©ative pour accompagner les exp√©rimentations des statisticiens publics](https://hal.science/hal-04263723v1/document)

- [Utiliser RStudio sur l‚Äôenvironnement SSP Cloud](https://book.utilitr.org/01_R_Insee/Fiche_utiliser_Rstudio_SSPCloud.html){target="_blank"}, UtilitR
- [Formations et tutoriels du SSP Cloud](https://www.sspcloud.fr/formation){target="_blank"}
  - Nombreux tutos : Python, R, ML, Spark, Cartographie 
- [Doc SSP Cloud](https://docs.sspcloud.fr/){target="_blank"}
- [Principes du Datalab](https://docs.sspcloud.fr/content/principles.html){target="_blank"}


### Pour aller plus loin 

Nous n'avons pas vraiment eu l'occasion de parler des dessous de la plateforme. Elle est construite sur un cluster Kubernetes. Et vous avez la possibilit√© d'interragir avec kubernetes en ligne de commande. Je vous laisse d√©couvrir comment √ßa marche ici : https://github.com/olevitt/kubernetes
